# SocialPure Prototype - System Monitoringu i Analizy MediÃ³w SpoÅ‚ecznych

## ğŸ“‹ Opis projektu

Zaawansowana aplikacja Flask do monitorowania i analizy komentarzy z mediÃ³w spoÅ‚ecznych (Facebook). System automatyzuje caÅ‚y proces od scrapingu danych, poprzez inteligentnÄ… klasyfikacjÄ™, do generowania szczegÃ³Å‚owych raportÃ³w analitycznych.

**Kluczowe funkcjonalnoÅ›ci:**
- ğŸ” Scraping komentarzy z Facebook (integracja Apify)
- ğŸ¤– Inteligentna klasyfikacja komentarzy (Google Gemini API)
- ğŸ“Š Generowanie raportÃ³w analitycznych w formacie PDF/DOCX
- ğŸ“ˆ Wizualizacja wynikÃ³w i trendÃ³w
- ğŸ”„ ModuÅ‚owa architektura umoÅ¼liwiajÄ…ca Å‚atwe rozszerzenia
- ğŸ›¡ï¸ ObsÅ‚uga bÅ‚Ä™dÃ³w i logging operacji

## ğŸ—ï¸ Architektura projektu

```
SocialPure_prototype/
â”œâ”€â”€ app.py                          # GÅ‚Ã³wny plik Flask (entry point)
â”œâ”€â”€ config.py                       # Konfiguracja i zmienne Å›rodowiskowe
â”œâ”€â”€ requirements.txt                # ZaleÅ¼noÅ›ci projektu
â”œâ”€â”€ .env.example                    # Szablon zmiennych Å›rodowiskowych
â”‚
â”œâ”€â”€ models/                         # Modele danych
â”‚   â”œâ”€â”€ scraping_job.py            # Model zadania scrapingu
â”‚   â”œâ”€â”€ scraping_result.py         # Model wyniku scrapingu
â”‚   â”œâ”€â”€ category_key.py            # Model klucza kategorii
â”‚   â””â”€â”€ classification_result.py   # Model wyniku klasyfikacji
â”‚
â”œâ”€â”€ services/                       # Logika biznesowa - orchestration
â”‚   â”œâ”€â”€ scraping_orchestrator.py   # Koordynacja procesu scrapingu
â”‚   â”œâ”€â”€ classification_orchestrator.py # Koordynacja klasyfikacji
â”‚   â”œâ”€â”€ apify_service.py           # Integracja z Apify API
â”‚   â”œâ”€â”€ facebook_scraper.py        # Scraper Facebook (Apify Actor)
â”‚   â”œâ”€â”€ facebook_search.py         # Wyszukiwanie na Facebook
â”‚   â”œâ”€â”€ query_generator.py         # Generowanie zapytaÅ„ wyszukiwania
â”‚   â”œâ”€â”€ gemini_service.py          # Integracja z Google Gemini
â”‚   â”œâ”€â”€ report_service.py          # Generowanie raportÃ³w
â”‚   â”œâ”€â”€ visualization_service.py   # Tworzenie wizualizacji
â”‚   â”œâ”€â”€ workflow_orchestrator.py   # GÅ‚Ã³wny orchestrator przepÅ‚ywu
â”‚   â”œâ”€â”€ job_storage.py             # Przechowywanie statusu zadaÅ„
â”‚   â”œâ”€â”€ storage_service.py         # ObsÅ‚uga przechowywania danych
â”‚   â””â”€â”€ logger.py                  # System logowania
â”‚
â”œâ”€â”€ blueprints/                     # Flask blueprints - routy i endpoints
â”‚   â”œâ”€â”€ scraping.py                # GÅ‚Ã³wne endpointy aplikacji
â”‚   â””â”€â”€ api.py                     # API endpoints
â”‚
â”œâ”€â”€ utils/                          # NarzÄ™dzia pomocnicze
â”‚   â”œâ”€â”€ helpers.py                 # Funkcje pomocnicze
â”‚   â””â”€â”€ validators.py              # Walidacja danych wejÅ›ciowych
â”‚
â”œâ”€â”€ templates/                      # Szablony HTML
â”‚   â”œâ”€â”€ base.html                  # Szablon bazowy
â”‚   â””â”€â”€ scraping/                  # Szablony widokÃ³w
â”‚       â”œâ”€â”€ index.html             # Strona gÅ‚Ã³wna
â”‚       â”œâ”€â”€ classification.html    # Widok klasyfikacji
â”‚       â”œâ”€â”€ classification_results.html # Wyniki klasyfikacji
â”‚       â”œâ”€â”€ results.html           # Wyniki scrapingu
â”‚       â”œâ”€â”€ logs.html              # Logi systemu
â”‚       â””â”€â”€ error.html             # Strona bÅ‚Ä™du
â”‚
â”œâ”€â”€ static/                         # Pliki statyczne
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css              # Stylizacja
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ main.js                # Skrypty gÅ‚Ã³wne
â”‚       â””â”€â”€ classification.js      # Skrypty klasyfikacji
â”‚
â””â”€â”€ data/                           # Przechowywanie wynikÃ³w zadaÅ„
```

## ğŸš€ Szybki start

### Wymagania
- Python 3.9+
- pip

### Instalacja

1. **Sklonuj repozytorium:**
   ```bash
   git clone https://github.com/Mikele-Kochas/SocialPure_prototype.git
   cd SocialPure_prototype
   ```

2. **Zainstaluj zaleÅ¼noÅ›ci:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Skonfiguruj zmienne Å›rodowiskowe:**
   ```bash
   cp .env.example .env
   ```
   Edytuj `.env` i uzupeÅ‚nij:
   - `APIFY_API_TOKEN` - token z https://apify.com
   - `GEMINI_API_KEY` - klucz API z https://aistudio.google.com

4. **Uruchom aplikacjÄ™:**
   ```bash
   python app.py
   ```
   Aplikacja bÄ™dzie dostÄ™pna pod adresem `http://127.0.0.1:5000`

## ğŸ“Š PrzepÅ‚yw pracy

```
1. UÅ¼ytkownik wprowadza dane (marka, daty)
         â†“
2. System uruchamia scraping Facebook (Apify Actor)
         â†“
3. System generuje klucz kategorii (Gemini Flash)
         â†“
4. System klasyfikuje komentarze (Gemini Flash Lite)
         â†“
5. System generuje raport i wizualizacje (Gemini Flash)
         â†“
6. UÅ¼ytkownik przeglÄ…da wyniki w interfejsie webowym
```

## ğŸ”‘ Komponenty systemu

### 1. **Scraping Module**
- Wyszukiwanie wzmianek marki na Facebook
- Zbieranie komentarzy z postÃ³w, grup, wydarzeÅ„
- Ekstrakcja metadanych (autorzy, czasy, oddziaÅ‚ywanie)

### 2. **Classification Module**
- Generowanie inteligentnego klucza kategorii na podstawie komentarzy
- Klasyfikacja kaÅ¼dego komentarza do odpowiedniej kategorii
- Wsparcie dla sentimentu i intent analysis

### 3. **Report Module**
- Generowanie raportÃ³w w PDF/DOCX
- Podsumowanie iloÅ›ciowe i jakoÅ›ciowe
- Rekomendacje na podstawie analizy

### 4. **Visualization Module**
- Wykresy trendÃ³w
- Mapy ciepÅ‚a kategorii
- Diagramy sentimentu

## ğŸ“¦ ZaleÅ¼noÅ›ci

**GÅ‚Ã³wne biblioteki:**
- **Flask 3.0+** - framework webowy
- **google-generativeai** - API Google Gemini
- **apify-client** - klient Apify
- **pandas** - analiza danych
- **matplotlib** - wizualizacje
- **python-docx, xhtml2pdf** - generowanie raportÃ³w

PeÅ‚na lista w `requirements.txt`

## âš™ï¸ Konfiguracja

### Zmienne Å›rodowiskowe (.env)
```
# API Keys (WYMAGANE)
APIFY_API_TOKEN=your_token_here
GEMINI_API_KEY=your_key_here

# Flask Configuration
SECRET_KEY=your-secret-key
DEBUG=False

# Limity
MAX_RESULTS=20
MAX_ACTOR_RESULTS=100
SCRAPING_TIMEOUT=300
```

## ğŸ¯ GÅ‚Ã³wne endpointy

- `GET /` - Strona gÅ‚Ã³wna
- `POST /scrape` - Uruchamia scraping
- `GET /results/<job_id>` - Wyniki scrapingu
- `POST /classify` - Uruchamia klasyfikacjÄ™
- `GET /classification_results/<job_id>` - Wyniki klasyfikacji
- `GET /logs` - Logi systemu
- `GET /report/<job_id>` - Pobieranie raportu

## ğŸ” RozwiÄ…zywanie problemÃ³w

### BÅ‚Ä…d: "APIFY_API_TOKEN nie jest ustawiony"
- Upewnij siÄ™, Å¼e `.env` zawiera prawidÅ‚owy token
- Plik `.env` powinien byÄ‡ w gÅ‚Ã³wnym katalogu projektu

### BÅ‚Ä…d podczas scrapingu
- SprawdÅº poÅ‚Ä…czenie internetowe
- Weryfikuj limit API Apify
- SprawdÅº logi w `/logs`

## ğŸ“ Licencja

MIT License - patrz plik LICENSE

## ğŸ‘¤ Autor

Mikele-Kochas


---

**Status:** Prototype (w aktywnym rozwoju)

